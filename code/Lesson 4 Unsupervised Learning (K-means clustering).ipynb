{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# magic! (don't worry about this)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us import some useful things\n",
    "from lib import *\n",
    "from classifiers import *\n",
    "#from graphs import *\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans as km_official\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's start with some simulated data in 2 dimensions so we can visualize how the algortihm works\n",
    "np.random.seed(1234)\n",
    "x1=np.random.uniform(1,5,[50,1])\n",
    "y1=np.random.uniform(5,10,[50,1])\n",
    "\n",
    "x2=np.random.uniform(15,20,[50,1])\n",
    "y2=np.random.uniform(10,15,[50,1])\n",
    "\n",
    "x3=np.random.uniform(8,14,[50,1])\n",
    "y3=np.random.uniform(4,15,[50,1])\n",
    "\n",
    "\n",
    "x=np.concatenate((x1,x2,x3),axis=0)\n",
    "y=np.concatenate((y1,y2,y3),axis=0)\n",
    "\n",
    "data=np.concatenate((x,y),axis=1)\n",
    "\n",
    "plt.plot(x,y,'bo')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "print(\"dimensions of data:\"+str(data.shape[0])+\" x \" + str(data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select k ;this will be the number of classes that you will use to group the data\n",
    "K=None #replace 'None' with a value for K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now, we define all the helper functions we use in the K-means algorithm. If you feel like a taking on a bigger challenge, you can also write the algorithm yourself from scratch without using our helper function. To do this, write your code in the \"kmeans\" function in the file \"classifiers_skeleton.py\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO write a function to randomly initialize K centroids in the data \n",
    "\n",
    "#make sure each centroid falls within the range of the observed data in the x & y dimension \n",
    "#hint: the following numpy functions may be useful to you \n",
    "def random_val_in_range(low,high): \n",
    "    return low+(float(high)-low)*np.random.random()\n",
    "\n",
    "#inputs: data is your data matrix with samples in the rows and features in the columns. \n",
    "#output: an array of centroids. For example, if K=3, and we have 2-dimensional data (2 features), \n",
    "#we would return a np.array with dimensions 3x2\n",
    "\n",
    "def initialize_centroids(data,K):\n",
    "    samples,features=data.shape \n",
    "    centroids=np.zeros((K,features))#create an array to store your centroids. You will update these values. \n",
    "    np.random.seed(1234)\n",
    "    #your code here! \n",
    "    return centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: import the euclidean distance function that you wrote when we did the K-Nearest Neighbors algorithm \n",
    "#(hint look at the import statements at the top of this file)\n",
    "#you use \"import\" to pull in code from other Python files to avoid having to copy it over and over into multiple\n",
    "#files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: write a function to find the nearest centroid to each point in a dataset \n",
    "#data in our example will be a 150x2 np.array and centroids will be a 3x2 np.array \n",
    "#hint: use your euclidean_distance function to loop over each point and loop over each centroid to calculate the \n",
    "#euclidean distance-- so 2 nested \"for\" loops. \n",
    "#although our specific example is 2 dimensional, your function should work with higher dimension data! \n",
    "\n",
    "#the output will be a list of labels 1 through K for each datapoint. \n",
    "def get_labels(centroids,data): \n",
    "    labels=[]  \n",
    "    num_centroids,num_features_centroids=centroids.shape \n",
    "    num_datapoints,num_features_data=data.shape \n",
    "    #sanity check -- your centroids and your data points should have the same number of features! \n",
    "    print(\"num_features_centroids: \" + str(num_features_centroids) + \" should equal num_features_data: \"+str(num_features_data))\n",
    "    #your code here! \n",
    "    return labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: write a function that will update the K-means centroids based on the labels that were calculated above. \n",
    "\n",
    "#inputs: a np.array of size datapoints x features ( so 150 datapoints x 2 features in our example)\n",
    "#labels: a list of K labels that were assigned to the datapoints. \n",
    "#K : number of clusters to generate\n",
    "\n",
    "#output: a np.array of updated centroids. This array will be of size K x features (i.e. 3 centroids with 2 features\n",
    "#will mean you return a 3x2 array)\n",
    "def get_centroids(data,labels,K):\n",
    "    num_datapoints,num_features=data.shape \n",
    "    centroids=np.zeros((K,num_features)) #update the values in this array as you calculate your centroids. \n",
    "    return centroids \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Check to see if the algorithm should stop \n",
    "#There are 2 conditions for the algorithm to stop: \n",
    "# 1. The cluster labels for the datapoints have not changed since the previous iteration \n",
    "# 2. The algorithm has exceeded the maximum number of iterations \n",
    " \n",
    "#inputs: \n",
    "# cur_iter -- the current iteration of the algorithm \n",
    "# max_iter -- the maximum allowed iterations of the algorithm \n",
    "# labels_old -- the labels that were assigned to the datapoints in the previous iteration \n",
    "# labels_new -- the labels that have been assigned to the datapoints in the most recent iteration \n",
    "\n",
    "#output: \n",
    "#The function returns \"True\" if we are finished, \"False\" if we are not finished\n",
    "def are_we_done(cur_iter,max_iter,labels_old,labels_new):\n",
    "    if labels_old==None: #this is an edge case -- the first time we iterate through the algorithm,labels_old will be None\n",
    "        return False \n",
    "    finished=False #if either of the conditions below are satisfied, change finished to True. \n",
    "    #check condition 1: \n",
    "    #your code here! \n",
    "    #check condition 2: \n",
    "    #your code here! \n",
    "    return finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Putting everything together. \n",
    "\n",
    "#Here, we use the functions you have implemented above to write the full K-means clustering algorithm. \n",
    "#The kmeans function accepts a np.array of data and a value for K, and returns a list of labels for your datapoints. \n",
    "def kmeans(data,K,max_iter): \n",
    "    #randomly initialize the centroids \n",
    "    centroids=initialize_centroids(data,K)\n",
    "    cur_iter=0 \n",
    "    labels_old=None \n",
    "    while True: \n",
    "        #assign cluster labels \n",
    "        labels=get_labels(centroids,data)\n",
    "        #check if we are done \n",
    "        finished=are_we_done(cur_iter,max_iter,labels_old,labels)\n",
    "        if finished: \n",
    "            break #exit the loop \n",
    "        else: \n",
    "            cur_iter+=1 #update the iteration number \n",
    "            labels_old=labels # update the labels_old variable\n",
    "            centroids=get_centroids(data,labels,K) #recalculate the centroids \n",
    "    #we have broken out of the while loop above, so we are finished. \n",
    "    #return the labels that have been calculated \n",
    "    return labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We test the k-means algorithm on our example dataset \n",
    "\n",
    "#if you wrote your code from scratch, uncomment the following import statement: \n",
    "#from classifiers_skeleton import * \n",
    "labels=kmeans(data,K,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot your labeled data \n",
    "plt.scatter(data[:,0],data[:,1],s=60,c=labels)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, let's compare your algorithm to the 'official' implementation from Python \n",
    "#you may not get exactly the same answer (think about why that would be), but the color groups in the \n",
    "#plots should look fairly similar. \n",
    "\n",
    "kobj=km_official(n_clusters=K)\n",
    "labels_official=kobj.fit_predict(data)\n",
    "plt.scatter(data[:,0],data[:,1],s=60,c=labels_official)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run K-means clustering on our cancer dataset (this is a good way to test your implementation in high-dimensional space)\n",
    "# load the data\n",
    "microarray_file_name = '../data/prostate_normal_tumor_matrix.txt'\n",
    "labels_file_name = '../data/prostate_normal_tumor_labels.txt'\n",
    "data_store = DataSet(microarray_file_name, labels_file_name) # Data\n",
    "data=data_store.all_data\n",
    "true_labels=data_store.labels\n",
    "print(data.shape)\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cluster your dataset into 2 classes \n",
    "K=2 \n",
    "#your code here\n",
    "labels=None #replace None with the labels generated by your k-means algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the 'True' labels for the dataset \n",
    "from sklearn.manifold import TSNE \n",
    "#we project our 12533-dimensional data into 2 dimensions for visualization: \n",
    "model=TSNE(n_components=10,random_state=0)\n",
    "data2d=model.fit_transform(data)\n",
    "plt.scatter(data2d[:,0],data2d[:,1],s=60,c=true_labels)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the labels generated by your algorithm \n",
    "plt.scatter(data2d[:,0],data2d[:,1],s=60,c=labels)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
